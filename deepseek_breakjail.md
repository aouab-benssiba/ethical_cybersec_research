# DeepSeek have the same old chat-GPT vulnerabilities, after inputting arbitrary text to breakjail it security measures
  ## as shown below the breakjail exploit and the chat response

![Screenshot 2025-01-31 203731](https://github.com/user-attachments/assets/46d6da74-3b92-4644-a9cf-d62a11daf6bb)

![Screenshot 2025-01-31 204456](https://github.com/user-attachments/assets/85725c29-7934-4624-b172-a94c1749e2b1)

![Screenshot 2025-01-31 203801](https://github.com/user-attachments/assets/a277812b-b419-40fb-862f-1069ef8d878f)

## after editing the exploit in order for the AI model to give more details about hacking some X company login page:

![Screenshot 2025-01-31 205243](https://github.com/user-attachments/assets/d93ae731-8b1a-40d8-a7a6-bca306e317fa)
![Screenshot 2025-01-31 205219](https://github.com/user-attachments/assets/b04e1abb-af8f-4fd3-a89d-e9dc8b556d22)
![Screenshot 2025-01-31 204456](https://github.com/user-attachments/assets/7be5c5af-c260-4992-9741-deb98d70ef6a)
![Screenshot 2025-01-31 203801](https://github.com/user-attachments/assets/cbdf305f-ba54-4915-9c5d-392beba63864)

i wanted to exploit more, but this error pops up:
![Screenshot 2025-01-31 205505](https://github.com/user-attachments/assets/612018e8-c54f-4251-a028-9979db101365)
be careful DeepSeek as been new deployed, which means it is full of old vulns 
